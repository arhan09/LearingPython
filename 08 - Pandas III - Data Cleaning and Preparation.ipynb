{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.4 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "7dae6437c12b1d87f00e0e10a4bd22be66a3b8ec05fb1161d95372f28c39fa9e"
    },
    "colab": {
      "name": "08 - Pandas II - Data Cleaning and Preparation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/recervictory/LearingPython/blob/Student/08%20-%20Pandas%20III%20-%20Data%20Cleaning%20and%20Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EltOY5JGWFLk"
      },
      "source": [
        "# Data Cleaning and Preparation\n",
        "\n",
        "During the course of doing data analysis and modeling, a *significant amount of time* is spent on data preparation: loading, cleaning, transforming, and rearranging. Such tasks are often reported to take up *80% or more of an analystâ€™s time*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOOw9XmiWFLn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import nan as NA # represent NaN as NA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqlK9iiLWFLm"
      },
      "source": [
        "## A. Handling Missing Data\n",
        "Missing data occurs commonly in many data analysis applications. One of the goals\n",
        "of pandas is to make working with missing data as painless as possible. For example,\n",
        "all of the descriptive statistics on pandas objects exclude missing data by default.\n",
        "\n",
        "The way that missing data is represented in pandas objects is somewhat imperfect,\n",
        "but it is functional for a lot of users. For numeric data, pandas uses the floating-point\n",
        "value NaN (Not a Number) to represent missing data.\n",
        "\n",
        "The built-in Python **None** value is also treated as NA in object arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEJ3z8oWFLn"
      },
      "source": [
        "string_data = pd.Series(['Kolkata', 'Delhi', np.nan, 'Bangalore'])\n",
        "string_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le97z5xwWFLo"
      },
      "source": [
        "string_data.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvjlbbcrWFLo"
      },
      "source": [
        "# The built-in Python None value is also treated as NA in object arrays:\n",
        "string_data[0] = None\n",
        "string_data.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZgbAWUpWFLp"
      },
      "source": [
        "### NA handling methods\n",
        "- `dropna` Filter axis labels based on whether values for each label have missing data, with varying thresholds for how much missing data to tolerate.\n",
        "- `fillna` Fill in missing data with some value or using an interpolation method such as 'ffill' or 'bfill'.\n",
        "- `isnull` Return boolean values indicating which values are missing/NA.\n",
        "- `notnull` Negation of isnull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2a3HFoJWFLp"
      },
      "source": [
        "### Filtering Out Missing Data\n",
        "While you always have the option to do it by hand using `pandas.isnull` and boolean indexing, the `dropna` can be helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4TszFS5WFLq"
      },
      "source": [
        "data = pd.Series([1, NA, 3.5, NA, 7])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2PVOHc6WFLq"
      },
      "source": [
        "# Droping the Data\n",
        "data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUSuEg69WFLq"
      },
      "source": [
        "# This is equivalent to:\n",
        "data[data.notnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BsuulWhWFLr"
      },
      "source": [
        "With DataFrame objects, things are a bit more complex. You may want to drop rows\n",
        "or columns that are all NA or only those containing any `NAs`. \n",
        "The `dropna` by default drops **any row containing a missing value**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLfS4AUXWFLr"
      },
      "source": [
        " \n",
        " data = pd.DataFrame([[1., 6.5, 3.], [1., NA, NA], [NA, NA, NA], [NA, 6.5, 3.]])\n",
        " cleaned = data.dropna()\n",
        " cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2sxWtIwWFLs"
      },
      "source": [
        "# Passing how='all' will only drop rows that are all NA:\n",
        "data.dropna(how='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKySadvaWFLs"
      },
      "source": [
        "# To drop columns in the same way, pass axis=1:\n",
        "data[4] = NA\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlAIw98BWFLs"
      },
      "source": [
        "# Drop data column wise\n",
        "data.dropna(axis=1, how='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhB7RiUSWFLs"
      },
      "source": [
        "### Filling In Missing Data\n",
        "For most purposes, the fillna method is the workhorse function to use. Calling fillna with a **constant** replaces **missing values** with that value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkFsBVfWWlB2"
      },
      "source": [
        "df = pd.DataFrame(np.random.randn(7, 3), columns=['gold', 'silver', 'copper'])\n",
        "df.iloc[:4, 1] = NA\n",
        "df.iloc[:2, 2] = NA\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubh6cp0bW7o0"
      },
      "source": [
        "# Fill The missing values with Zero\n",
        "df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPWs7qYsXJRm"
      },
      "source": [
        "# Calling fillna with a dict, you can use a different fill value for each column:\n",
        "df.fillna({'silver': -1, 'copper': 1})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peUw5O3tYN0I"
      },
      "source": [
        "# fillna returns a new object, but you can modify the existing object in-place:\n",
        "df.fillna(0)\n",
        "print(df)\n",
        "df.fillna(0, inplace=True) # Important\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpiB4nzzZkrd"
      },
      "source": [
        "The same **interpolation** methods available for reindexing can be used with fillna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3cLrs8kYsec"
      },
      "source": [
        "# Creating Dataframe\n",
        "df = pd.DataFrame(np.random.randn(8, 3), columns=['gold', 'silver', 'copper'])\n",
        "df.iloc[2:, 1] = NA\n",
        "df.iloc[4:, 2] = NA\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgCWjwirZ4SP"
      },
      "source": [
        "# Fill 'NA' with forword fill method\n",
        "df.fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpH3JahKaGwQ"
      },
      "source": [
        "# limit by row\n",
        "df.fillna(method='ffill', limit=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-vjGuGOabYD"
      },
      "source": [
        "# you might pass the mean or median values\n",
        "df.fillna(df.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4HMO--Br_sz"
      },
      "source": [
        "df.fillna(df.mean(),inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD_27zxCqwQg"
      },
      "source": [
        "df['category'] = [NA,'A','B',NA,'A','C','A','B']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EECAoCArll9"
      },
      "source": [
        "df['category'].fillna(df['category'].mode()[0], inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDP2Eg-rKiXl"
      },
      "source": [
        "## B. Data Transformation\n",
        "\n",
        "### Removing Duplicates\n",
        "Duplicate rows may be found in a DataFrame for any number of reasons. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W_8vri8KhB3"
      },
      "source": [
        "data = pd.DataFrame({'city': ['kolkata', 'delhi'] * 3 + ['delhi'],'count': [1, 1, 2, 3, 3, 4, 4]})\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIXiCffVMFV1"
      },
      "source": [
        "The DataFrame method `duplicated()` returns a **boolean Series** indicating whether each row is a duplicate (has been observed in a previous row) or not:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gHG-m6KMC_H"
      },
      "source": [
        "data.duplicated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5AUcKrZMp86"
      },
      "source": [
        "The `drop_duplicates()` returns a DataFrame where the duplicated array is False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APi8MYEpLkUG"
      },
      "source": [
        "data.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeNFgOzXLncS"
      },
      "source": [
        "data['price'] = np.random.randint(10,100,size=7)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUN_LZAvNrot"
      },
      "source": [
        " # Drop duplicate by column\n",
        " data.drop_duplicates(['city'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCBrFMF9OVij"
      },
      "source": [
        "### Transforming Data Using a Function or Mapping\n",
        "For many datasets, you may wish to perform some transformation based on the values in an array, Series, or column in a DataFrame. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWGXGsydN_57"
      },
      "source": [
        "data = pd.DataFrame({'city':['New York','Delhi','Kolkata','Chicago','Las Vegas'], \n",
        "                     'pupulation': np.random.randint(100000,1000000000,size=5)\n",
        "                     })\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8d1fc-VP67O"
      },
      "source": [
        "city_to_country = {'new york':'usa','delhi':'india','kolkata':'india','chicago':'usa','las vegas':'usa'}\n",
        "city_to_country"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bwP8Ou_QbKP"
      },
      "source": [
        "# We Need to cheack the data type\n",
        "data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDbrjR_kQsMd"
      },
      "source": [
        "data['city'] = data['city'].str.lower()\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlW5uW66Reyj"
      },
      "source": [
        "data['country'] = data['city'].map(city_to_country)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKeQs9gfSATd"
      },
      "source": [
        "### Replacing Values\n",
        "Filling in missing data with the `fillna()` method is a special case of more general value replacement. As youâ€™ve already seen, `map()` can be used to modify a subset of values in an object but replace provides a simpler and more flexible way to do so. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oGRkLVwRubh"
      },
      "source": [
        "data['pupulation'] = data['pupulation'].replace([843448647,127963973\t],np.nan)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK7UyJ6CTobP"
      },
      "source": [
        "### Detecting and Filtering Outliers\n",
        "Filtering or transforming **outliers** is largely a matter of applying array operations. Consider a DataFrame with some normally distributed data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdGdrzDrSm0p"
      },
      "source": [
        "data = pd.DataFrame(np.random.randn(1000, 4),columns=['Aaba','Baba','Caca','Dada'])\n",
        "\n",
        "# Lets find out the outliers\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feDtvMgGUkqZ"
      },
      "source": [
        "data[np.abs(data['Caca']) > 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga5Tr_5QVQqL"
      },
      "source": [
        "# Detecting outleirs from any columns in the dataframe\n",
        "\n",
        "data[(np.abs(data) > 3).any(1)] # axis = 1 i.e column wise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXNrY9wbXTb3"
      },
      "source": [
        "data[(np.abs(data) > 3).all(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQqQYN9NXXnE"
      },
      "source": [
        "new_row = {'Aaba' : 4,\t'Baba':4,\t'Caca': -4,\t'Dada': -4}\n",
        "data = data.append(new_row,ignore_index=True)\n",
        "data[(np.abs(data) > 3).all(1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9aFzIt6YnKP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYT7FM56w49Y"
      },
      "source": [
        "# Project: Risk of being drawn into online sex work\n",
        "\n",
        "### Context\n",
        "This database was used in the paper: Covert online ethnography and machine learning for detecting individuals at risk of being drawn into online sex work. 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), Barcelona, Spain, 28-31 August.\n",
        "\n",
        "### Content\n",
        "The database includes data scraped from a European online adult forum. Using covert online ethnography we interviewed a small number of participants and determined their risk to either supply or demand sex services through that forum. This is a great dataset for semi-supervised learning.\n",
        "\n",
        "### Inspiration\n",
        "How can we identify individuals at risk of being drawn into online sex work? The spread of online social media enables a greater number of people to be involved into online sex trade; however, detecting deviant behaviors online is limited by the low available of data. To overcome this challenge, we combine covert online ethnography with semi-supervised learning using data from a popular European adult forum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7d7ldUQyWca"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaqtbgM-yK84"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings; warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr55C83rya2a"
      },
      "source": [
        "df = pd.read_csv('/content/online_sex_work.csv', index_col=0)\n",
        "df = df.iloc[: 28831, :]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_wXTIB-ymwW"
      },
      "source": [
        "# Understand the Data Types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16hSyAZyzLs8"
      },
      "source": [
        "## Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKt4YaS9zQrQ"
      },
      "source": [
        "### Change datatype for some features\n",
        "\n",
        "Data in a number of features that contain numerical data could be converted into pure numbers (integers), which would take less memory and could be interpreted more easily by machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oympJlMjy3Ym"
      },
      "source": [
        "df.index = df.index.astype(int)\n",
        "df['Number_of_advertisments_posted'] = df['Number_of_advertisments_posted'].astype(int)\n",
        "df['Number_of_offline_meetings_attended'] = df['Number_of_offline_meetings_attended'].astype(int)\n",
        "df['Profile_pictures'] = df['Profile_pictures'].astype(int)\n",
        "df['Friends_ID_list'] = df['Friends_ID_list'].astype(str)\n",
        "df['Risk'] = df['Risk'].astype(str)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqj1TlUpzgfT"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jB7rEZ0z2sH"
      },
      "source": [
        "# cheack the Error\n",
        "# df['Number_of_Comments_in_public_forum'] = df['Number_of_Comments_in_public_forum'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJUltVdez-5w"
      },
      "source": [
        "df['Number_of_Comments_in_public_forum'] = df['Number_of_Comments_in_public_forum'].str.replace(' ', '').astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYvNIdpTgWt1"
      },
      "source": [
        "### Counting the Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugRatz1adCYF"
      },
      "source": [
        "# Count of missing values column wise\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbL1-ijfVJE"
      },
      "source": [
        "### Convert `Gender` to binary data\n",
        "\n",
        "In the `Gender` column, We fill some missing values using some simple conditions (if the entry is, for example, homosexual, and looking for men, we fill that entry with `male`), using the `fill_gender_na` function below. Then in every entry, we change the data to whether it specifies `female` or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeE2N25bgIGz"
      },
      "source": [
        "def fill_gender_na(row):\n",
        "    if row['Sexual_orientation'] == 'Homosexual':\n",
        "        if row['Looking_for'] == 'Men':\n",
        "            return 'male'\n",
        "        elif row['Looking_for'] == 'Women':\n",
        "            return 'female'\n",
        "    elif row['Sexual_orientation'] == 'Heterosexual':\n",
        "        if row['Looking_for'] == 'Men':\n",
        "            return 'female'\n",
        "        elif row['Looking_for'] == 'Women':\n",
        "            return 'male'\n",
        "    return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVSCic_pghp7"
      },
      "source": [
        "## Fill the missing data\n",
        "fill_values = df.apply(fill_gender_na, axis=1)\n",
        "df['Gender'].fillna(fill_values, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-4lcqsxhHlN"
      },
      "source": [
        "# Lets check the missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvkkJxjShKCy"
      },
      "source": [
        "# Add missing value with summary statistics \n",
        "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLSsYnIOheq9"
      },
      "source": [
        "# Lets check the missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a708xJHmjND3"
      },
      "source": [
        "### Insert new Binary column named 'Female'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0wmwLVtjMBT"
      },
      "source": [
        "df.insert(0, 'Female', df['Gender'] == 'female')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2rUDYrSpREa"
      },
      "source": [
        "### Missing values in `Location`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkFMIwg0pSDR"
      },
      "source": [
        "df['Location'].fillna(df['Location'].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrCEe6OCj9Ye"
      },
      "source": [
        "### Decimal points in `Age`\n",
        "\n",
        "We replace all commas (European decimal separator) with periods, while handling some unformatted values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRyFqmK-kQe6"
      },
      "source": [
        "def comma_replace(obj):\n",
        "  return obj.replace(\",\",\".\")\n",
        "\n",
        "df['Age'].head().apply(comma_replace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2MQK_OkiI7o"
      },
      "source": [
        "# Lets do with single line with lambda\n",
        "df['Age'] = df['Age'].apply(lambda obj: obj.replace(',', '.'))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hOfH4E6kOfS"
      },
      "source": [
        "# Error: Convering age to numeric\n",
        "pd.to_numeric(df['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWbC8mgTomBK"
      },
      "source": [
        "# Method 1\n",
        "df['Age'] = df['Age'].replace('???', np.nan)\n",
        "df['Age'] = df['Age'].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TKtFqZcn9gG"
      },
      "source": [
        "# Method 2\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "895_zlb5o5Qk"
      },
      "source": [
        "# Lets check the missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sAi3mBWo878"
      },
      "source": [
        "df['Age'].fillna(df['Age'].mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOrz3JA7pGEU"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1IxWRiypf-S"
      },
      "source": [
        "### Convert `Verification` to binary data\n",
        "\n",
        "In every entry, we change the data to whether the user is verified or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJWvVOHLpfHk"
      },
      "source": [
        "df['Verification'] = df['Verification'] != 'Non_Verified'\n",
        "df[['Verification']].head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}